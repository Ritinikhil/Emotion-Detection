# Real-Time Facial Emotion Recognition with Cloud-Optimized Logging

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.9+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ† GitHub Achievements

![GitHub Achievements](https://github-profile-trophy.vercel.app/?username=Ritinikhil&theme=darkhub&no-frame=true&margin-w=15)

A lightweight, real-time facial emotion recognition system achieving **80% accuracy on RAF-DB**, **50+ FPS on CPU**, and **~80% storage reduction** through cloud-optimized compression.

## ğŸ¯ Key Features

- **Lightweight Architecture**: SimpleFERCNN with only **1.2M parameters**
- **Real-Time Performance**: 50â€“60 FPS on a standard CPU (Intel Core i5)
- **Robust Preprocessing**: Adaptive low-light enhancement and pose normalization
- **Cloud-Optimized Logging**: ~80% storage reduction (21.7 KB â†’ 4.3 KB per image)
- **Superior Generalization**: Outperforms ResNet-18 and CBAM on constrained datasets

## ğŸ“Š Performance Summary

| Model                   | Accuracy (RAF-DB) | Parameters | Trainâ€“Test Gap | Inference Time |
|-------------------------|------------------|------------|----------------|----------------|
| **SimpleFERCNN (Ours)** | **80.0%**        | 1.2M       | 16%            | ~15â€“20 ms      |
| ResNet-18               | 78.49%           | 11.2M      | 21%            | ~80â€“100 ms     |
| CBAM-Enhanced CNN       | 78.81%           | 1.3M       | 18%            | ~25â€“30 ms      |

**Dataset Results**
- FER2013: 62% accuracy
- RAF-DB: 80% accuracy

## ğŸ—ï¸ System Architecture

Input (640Ã—480) â†’ Face Detection â†’ Adaptive Preprocessing â†’ SimpleFERCNN â†’ Emotion Output â†’ Cloud Logging (WebP + Zlib + Base91)

### Pipeline Components

**Adaptive Preprocessing**
- Low-light enhancement using brightness-aware gamma correction and CLAHE
- Pose normalization using MediaPipe face landmarks (eye-level alignment, yawâ€“pitchâ€“roll normalization)

**Lightweight CNN (SimpleFERCNN)**
- Input: 48Ã—48 grayscale face image
- 3 convolutional blocks with batch normalization and max-pooling
- Fully connected layers with dropout
- Output: 7 emotion classes (Softmax)

**Cloud-Optimized Compression & Logging**
- Face ROI extraction
- WebP encoding (quality â‰ˆ 80)
- Zlib compression
- Base91 text encoding
- Firebase Realtime Database storage
- Storage reduced from ~21.7 KB to ~4.3 KB per sample

## ğŸš€ Quick Start

### Installation

```bash
git clone https://github.com/ritinikhil/Major-FER.git
cd Major-FER
pip install -r requirements.txt
setup firebase cloud 
```

### Requirements

- Python 3.8+
- PyTorch â‰¥ 1.9.0
- torchvision â‰¥ 0.10.0
- opencv-python â‰¥ 4.5.0
- mediapipe â‰¥ 0.8.9
- firebase-admin â‰¥ 5.0.0
- numpy â‰¥ 1.21.0

## ğŸ§  Training

```bash
# Train on FER2013
python train.py --dataset FER2013 --epochs 50 --batch_size 64

# Train on RAF-DB
python train.py --dataset RAF-DB --epochs 50 --batch_size 64
```

## ğŸ¥ Real-Time Inference

```bash
# Webcam input
python realtime_demo.py --model checkpoints/fercnn_raf.pth

# Video file input
python realtime_demo.py --model checkpoints/fercnn_raf.pth --input path/to/video.mp4

# With cloud logging enabled
python realtime_demo.py --model checkpoints/fercnn_raf.pth --cloud-logging
```

Ensure Firebase credentials are configured via environment variables or a config file.

## ğŸ“ Project Structure

```
Major-FER/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ fercnn.py
â”‚   â”œâ”€â”€ resnet18.py
â”‚   â””â”€â”€ cbam.py
â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ low_light.py
â”‚   â”œâ”€â”€ pose_alignment.py
â”‚   â””â”€â”€ face_detection.py
â”œâ”€â”€ compression/
â”‚   â”œâ”€â”€ roi_extractor.py
â”‚   â”œâ”€â”€ webp_encoder.py
â”‚   â””â”€â”€ base91_encoder.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ dataset.py
â”‚   â”œâ”€â”€ train_utils.py
â”‚   â””â”€â”€ firebase_client.py
â”œâ”€â”€ train.py
â”œâ”€â”€ evaluate.py
â”œâ”€â”€ realtime_demo.py
â”œâ”€â”€ dashboard.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ”¬ Key Findings

SimpleFERCNN (1.2M parameters) achieves **80.0% accuracy on RAF-DB** with a **16% trainâ€“test gap**, outperforming deeper baselines such as ResNet-18 and CBAM-enhanced CNNs.

Training separate models for FER2013 and RAF-DB yields significantly better generalization due to domain differences between controlled grayscale images and in-the-wild color images.

Adaptive preprocessing improves robustness under low-light and pose variations without increasing model complexity.

ROI-based compression reduces cloud storage requirements by ~80% while preserving facial expression details.

On a CPU-only setup (Intel Core i5-10400), the system sustains **30+ FPS end-to-end** without GPU acceleration.

## ğŸ“ Citation

```bibtex
@article{singh2026realtime,
  title={A Lightweight Multi-Model Framework for Robust Facial Emotion Recognition with Cloud-Optimised Logging},
  author={Singh, Nikhil and Dagar, Rohit and Garg, Animesh and Dass, Stephen A},
  journal={Under Review},
  year={2026}
}
```

## ğŸ¤ Contributing

Contributions are welcome. Please open an issue or submit a pull request for improvements or extensions.

## ğŸ“ License

This project is licensed under the MIT License.

## ğŸ‘¥ Authors

Nikhil Singh â€“ SRM Institute of Science and Technology  
Rohit Dagar â€“ SRM Institute of Science and Technology  
Animesh Garg â€“ SRM Institute of Science and Technology  
Dr. Stephen Dass A â€“ SRM Institute of Science and Technology  

## ğŸ™ Acknowledgments

Thanks to the FER2013 and RAF-DB creators, and the PyTorch, MediaPipe, and Firebase communities.

## ğŸ“§ Contact

For questions or collaboration, please use the GitHub Issues tab.

â­ If you find this repository useful, consider giving it a star!
